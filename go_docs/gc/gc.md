# 文档

## A Guide to the Go Garbage Collector（Go 垃圾回收器指南）

### 目录

* 引言
* Go 值存放在哪里
* 追踪式垃圾回收
* GC 周期
* 理解成本
* GOGC
* 内存上限（Memory limit）
* 延迟（Latency）
* 终结器、清理与弱指针
* 其他资源
* 关于虚拟内存的说明
* 优化指南

  * 识别成本
  * 消除堆分配
  * 与实现相关的优化
  * Linux 透明大页（THP）
* 附录：关于 GOGC 的附加说明

---

## 引言

本指南旨在帮助高级 Go 用户通过了解 Go 垃圾回收器（GC），更好地理解其应用的成本，并据此改进应用的资源利用率。本文不假设读者了解垃圾回收，但假设熟悉 Go 语言。

Go 语言负责安排 Go 值的存储；大多数情况下，开发者无需关心这些值存在哪里、为什么（以及是否）要这么做。但在实践中，这些值往往需要存放在计算机的物理内存中，而物理内存是有限的。因为有限，内存必须被谨慎管理并循环再利用，以避免程序运行中耗尽内存。Go 的实现负责按需分配与回收内存。

自动回收内存的另一个术语就是“垃圾回收”。从高层看，垃圾回收器（GC）通过识别哪些内存不再需要，代表应用回收内存。Go 标准工具链为每个应用提供一个运行时库，其中包含垃圾回收器。

需要注意，Go 规范并不保证存在本文描述的垃圾回收器，只保证 Go 值的底层存储由语言本身管理。这个“省略”是有意的，允许使用截然不同的内存管理技术。

因此，本文讨论的是 Go 语言的一个具体实现，未必适用于其他实现。更具体地说，以下内容适用于标准工具链（gc 编译器与工具）。gccgo 与 gollvm 使用非常相似的 GC 实现，许多概念适用，但细节可能不同。

此外，这是一份“活文档”，会随 Go 的最新发布而变化。本文当前描述的是 **Go 1.19** 的垃圾回收器。

---

## Go 值存放在哪里

在深入 GC 之前，先讨论不需要 GC 管理的内存。

例如，存放在局部变量中的**无指针** Go 值通常不会由 Go GC 管理，Go 会安排为其分配与词法作用域绑定的内存。一般而言，这比依赖 GC 更高效，因为编译器能预先确定何时释放该内存并发出相应的机器指令来清理。我们通常把以这种方式为 Go 值分配内存称为“**栈分配**”，因为空间位于 goroutine 的栈上。

当 Go 编译器无法确定值的生命周期，从而不能采用上述方式时，Go 值就会“**逃逸**”到堆上。“堆”可以看作是当 Go 值需要被放在某处时的兜底之处。把内存分配到堆上的行为通常称为“**动态内存分配**”，因为编译器与运行时几乎无法对这块内存的使用方式与可清理时间作出假设。这就是 GC 的用武之地：它识别并清理动态内存分配。

值可能逃逸到堆的原因有很多。一个原因是其大小动态决定。比如，一个切片的底层数组初始大小由变量而非常量决定。注意，逃逸具有**传递性**：如果某个值的引用被写入了另一个已经确定会逃逸的值中，那么该值也必须逃逸。

某个值是否逃逸，取决于其使用上下文与编译器的**逃逸分析**算法。试图精确枚举值何时逃逸是脆弱且困难的：算法本身相当复杂，且在不同 Go 版本之间会变化。关于如何识别哪些值逃逸、哪些不逃逸，见后文“消除堆分配”。

---

## 追踪式垃圾回收

垃圾回收可以指代多种自动回收内存的方法；例如引用计数。在本文语境下，垃圾回收指“**追踪式垃圾回收**”，它通过**传递性地沿指针**识别“存活”（正在使用中）的对象。

更严格地定义一些术语：

* **对象（Object）**：一块动态分配的内存，包含一个或多个 Go 值。
* **指针（Pointer）**：一个内存地址，引用对象内的任意值。这当然包括形如 `*T` 的 Go 值，也包括内建类型中的指针部分。字符串、切片、channel、map 与接口值都包含 GC 必须追踪的内存地址。

对象与通向其他对象的指针共同构成**对象图**。为了识别存活内存，GC 从程序的**根（roots）**开始遍历对象图：根是指那些**确定在用**的对象指针。例如局部变量与全局变量。遍历对象图的过程称为**扫描（scanning）**。你也会在 Go 文档中看到“是否**可达（reachable）**”这一说法，意思是对象能被扫描过程发现。注意，除了一个例外，一旦内存变为不可达，它就会一直不可达。

这个基本算法在所有追踪式 GC 中都通用。不同之处在于识别到存活内存后，GC 做什么。Go 的 GC 使用\*\*标记-清扫（mark-sweep）\*\*技术：为了记录进度，GC 会把遇到的值标记为“活”。一旦追踪完成，GC 会遍历整个堆内存，把未标记的内存置为可分配，即“**清扫（sweeping）**”。

另一种你可能熟悉的技术是把对象实际移动到新内存区域，并留下**转发表指针**，随后用它更新应用中的所有指针。我们把这种会移动对象的 GC 称为“**移动式 GC（moving GC）**”；而 Go 是**非移动式 GC**。

---

## GC 周期

因为 Go 的 GC 是标记-清扫式，它大体分两个阶段：**标记阶段**与**清扫阶段**。这似乎是同义反复，但包含一个重要洞见：在完全追踪完所有内存之前，**无法**把内存释放回可分配状态，因为可能仍有未扫描的指针让某对象存活。因此，清扫与标记必须完全分离。此外，当没有 GC 相关工作时，GC 也可能处于**关闭**状态。

GC 持续在这三个阶段之间轮转：清扫 → 关闭 → 标记，这称为**GC 周期**。为便于讨论，本文从清扫开始，随后关闭，再到标记。

接下来的小节将着重建立理解 GC 成本的直觉，帮助用户调整 GC 参数以获益。

---

## 理解成本

GC 本质上是建立在更复杂系统之上的复杂软件。试图理解 GC 并调整其行为时，很容易被细节淹没。本节提供一套用于推理 Go GC 成本及其调优参数的框架。

先看基于三个简单公理的 GC 成本模型：

1. GC 只涉及两种资源：**物理内存**与**CPU 时间**。

2. GC 的内存成本由**存活堆内存**、**标记阶段前新分配的堆内存**以及用于元数据的空间组成；即使后者与前者成比例，也远小于前二者。

   > 周期 N 的 GC 内存成本 = 周期 N-1 的存活堆 + 新堆

   存活堆是上一个 GC 周期判定为存活的内存；新堆是当前周期新分配的内存，最终可能存活也可能不存活。任一时刻的存活内存大小是**程序的属性**，GC 无法直接控制。

3. GC 的 CPU 成本可建模为：**每周期固定成本** + **与存活堆大小成比例的边际成本**。

   > 周期 N 的 GC CPU 时间 = 每周期固定成本 + 每字节平均成本 × 周期 N 找到的存活堆大小

   每周期固定成本包括每个周期恒定发生的事情，如为下轮 GC 初始化数据结构。该成本通常很小，仅为完整性而列出。

   GC 的大部分 CPU 成本来自**标记与扫描**，由边际成本捕获。平均标记与扫描成本取决于 GC 实现，也取决于程序行为。例如，指针越多，GC 至少需要访问的指针就越多，工作量越大。链表、树等结构也更难被并行遍历，提高了每字节平均成本。

该模型忽略了与**总堆内存**成比例的清扫成本（包括死亡内存，因为必须把它们变为可分配）。在 Go 当前实现中，清扫远快于标记与扫描，故相较之下可忽略。

这个模型虽然简单，但有效：它准确分类了 GC 的主导成本。它还告诉我们：在一定时间窗口内，GC 的**总 CPU 成本**取决于**GC 周期的总次数**。最后，模型内嵌了一个根本性的**时间/空间权衡**。

为说明这一点，考虑一个受限但有用的场景：**稳态（steady state）**。从 GC 视角，一个应用的稳态由以下性质定义：

* 应用的新内存分配速率（字节/秒）恒定。

  这意味着从 GC 视角，工作负载随时间大致相同。例如对一个 Web 服务，就是恒定的请求速率、平均相同类型请求、每个请求的平均生命周期大致不变。

* GC 的边际成本恒定。

  即对象图的统计特征，如对象大小分布、指针数量、数据结构平均深度等，在各周期间保持不变。

举例：某应用分配速率为 10 MiB/s，GC 扫描速率为 100 MiB/CPU-秒（假设值），且固定成本为 0。为简化，假设该应用的存活堆始终为 10 MiB（注意：存活堆恒定不代表新分配内存全部死亡，而是指每次 GC 后，旧堆与新堆的某种混合部分仍存活）。如果每个 GC 周期**恰好**每 1 个 CPU-秒发生一次，那么在稳态下，每次 GC 时总堆大小为 20 MiB。每次 GC 需要 0.1 个 CPU-秒完成工作，对应 10% 的开销。

如果把 GC 周期改为每 2 个 CPU-秒一次，那么每次 GC 时总堆为 30 MiB，但每次 GC 仍只需 0.1 个 CPU-秒。于是 GC 开销从 10% 降为 5%，代价是内存使用增加 50%。

这种开销变化体现出前述的**时间/空间权衡**。GC 频率是该权衡的核心：**GC 越频繁，内存用得越少；反之亦然**。那么 GC 实际多久运行一次？在 Go 中，决定何时启动 GC 的主要参数由用户控制。

---

## GOGC

从高层看，**GOGC** 用于在 GC CPU 与内存之间做权衡。

其工作方式是：在每个 GC 周期结束后，确定**下个周期的目标堆大小**（target heap size）。GC 的目标是在总堆大小超过目标堆大小之前完成一次收集。总堆大小定义为：上个周期末的存活堆大小 + 自上个周期以来应用新分配的堆内存。而目标堆大小定义为：

> 目标堆大小 = 存活堆 + （存活堆 + GC 根）× GOGC / 100

示例：假设某 Go 程序的存活堆 8 MiB，goroutine 栈 1 MiB，全局变量中的指针 1 MiB。若 GOGC=100，那么在下一次 GC 触发前可新分配的内存量为 10 MiB（即 10 MiB 的“工作量”的 100%），总堆峰值约为 18 MiB。若 GOGC=50，则为 50%（5 MiB）；若 GOGC=200，则为 200%（20 MiB）。

> 注意：自 Go 1.18 起，GOGC 把\*\*根集（root set）\*\*也计入；此前只计存活堆。很多情况下 goroutine 栈内存很小，存活堆占主导。但对拥有几十万 goroutine 的程序，早期 GC 会做出不佳判断。

**目标堆**控制 GC 频率：目标越大，GC 可越久再启动标记；反之亦然。尽管精确公式有助于估算，更好的理解方式是把 GOGC 视为一个用于在“GC CPU 与内存”之间**选取平衡点的参数**。关键要点：**将 GOGC 翻倍会使堆内存开销翻倍，并大致把 GC CPU 成本减半，反之亦然**（详见附录）。

> 注意：目标堆只是目标；有多种原因导致 GC 周期不会恰好在目标处结束。例如一次**足够大的分配**就可能超过目标。此外，还有超出我们简化模型之外的实现细节（参见“延迟”章节；完整细节见“其他资源”）。

GOGC 可通过环境变量 **GOGC**（所有 Go 程序识别）或 **runtime/debug.SetGCPercent** API 配置。

将 GOGC 设为 `off`（或 `SetGCPercent(-1)`）可**完全关闭 GC**（若内存上限不生效）。概念上等价于把 GOGC 设为无穷大，此时在触发 GC 前可新分配的内存不受限。

文中还提供了一个基于上述 GC 成本模型的交互可视化（此处略）。核心结论：**GOGC 越大，CPU 开销越小，但峰值内存按存活堆成比例增加；GOGC 越小，峰值内存越小，但 CPU 开销更大。**

> 说明：图中显示的是 CPU 时间，而非墙钟时间。如果程序只占用 1 个 CPU 且 100% 利用，则两者等价。现实中多核且并非持续 100% 利用，GC 对墙钟时间的影响会更低。

> 说明：Go GC 的最小**总堆大小**为 **4 MiB**；若 GOGC 计算出的目标低于此值，会被向上取整。可视化反映了这一细节。

另一个更动态的例子（此处略）展示了稳态下存活堆变化、分配速率在中途显著升高时，GC 频率如何随分配速率提高而更频繁。

---

## 内存上限（Memory limit）

直到 Go 1.19 之前，用户只能通过 GOGC 调整 GC 行为。虽然它非常适合设置权衡点，但**它没有考虑“可用内存是有限的”**这一事实。想象当存活堆发生瞬时峰值时：因为 GC 会选取与存活堆**成比例**的总堆大小，GOGC 就必须按峰值来配置——即便在通常情况下，较高的 GOGC 提供更好的权衡。

为此，Go 1.19 引入了**运行时内存上限**。它可通过环境变量 **GOMEMLIMIT** 或 **runtime/debug.SetMemoryLimit** 设置。

该内存上限为 Go 运行时可使用的内存总量设置一个**最大值**。用 `runtime.MemStats` 表示为：

> `Sys - HeapReleased`

等价地，用 `runtime/metrics` 表示为：

> `/memory/classes/total:bytes - /memory/classes/heap/released:bytes`

由于 Go GC 对堆内存用量有显式控制，它会基于**内存上限**和 Go 运行时使用的其他内存来设定**总堆大小**。

如果把内存上限降到低于 GOGC 所决定的峰值内存，GC 会**更频繁**地运行，以将峰值内存控制在上限之内。由此可以：

* 对于**瞬时峰值**，结合设置内存上限与调高 GOGC，可在**不突破上限**的同时，获得更好的资源经济性。
* 即使将 **GOGC=off**，**内存上限仍会被遵守**。这种配置在某种意义上“最大化资源经济性”：以维持内存上限所需的**最低 GC 频率**运行。

然而，内存上限并非没有代价，也并**不替代** GOGC 的实用性。

考虑当存活堆增长，导致总内存接近上限时会发生什么：如果把 GOGC 关掉，再逐步降低上限，程序总耗时会开始**无限增长**，因为 GC 为维持一个**不可能**的上限而不断运行。这种程序因持续 GC 而无法合理推进的情况称为 **thrashing（抖动/颠簸）**。它尤其危险，因为会实际上**卡住**程序。更糟的是，这正可能由我们试图避免的情形触发：一次足够大的瞬时峰值就可能导致程序无限期停滞！

在很多情况下，**无限停滞**比 OOM（内存不足）更糟，后者通常更快失败。

为此，内存上限定为**软性上限**。Go 运行时不保证在所有情况下都严格维持该上限；它只承诺会付出“合理努力”。这种放松对避免 thrashing 至关重要，因为它给 GC 一个**退路**：**允许**超出上限，以避免在 GC 中花费过多时间。

其内部机制是：GC 对在某时间窗口内可使用的**CPU 时间占比**设定上限（对非常短暂的 CPU 使用尖峰加入滞后）。当前该上限大约为 **50%**，窗口为 **2 × GOMAXPROCS CPU-秒**。限制 GC CPU 时间意味着 GC 工作会**被延迟**，同时 Go 程序可能继续分配新堆内存，甚至**超出内存上限**。

对于这个 50% 上限的直觉是：在内存充裕的最坏配置错误场景（上限设太低）中，程序最多**慢 2 倍**，因为 GC 最多能拿走 50% 的 CPU 时间。

> 注：文中可视化未模拟该 GC CPU 上限。

### 使用建议

* 当 Go 程序的**运行环境完全可控**，且**内存资源只被该程序占用**（如容器内存上限等“内存预留”）时，**建议使用内存上限**。

  * 例如把 Web 服务部署到有固定可用内存的容器中。
  * 经验法则：预留额外 **5–10%** 余量，以覆盖 Go 运行时**未知**的内存来源。
* 可**实时调整**内存上限以适应变化。

  * 例如 cgo 程序中，C 库阶段性地需要更多内存。
* 若 Go 程序可能与其他**去耦应用**共享有限内存，**不要**把 GOGC 设为 off 并配合内存上限。保留上限以抑制不良瞬时行为，但将 GOGC 设为适合平均情况的**较小**值更好。

  * 试图“为同住应用**预留内存**”常不可靠，除非完全同步（如子进程期间 Go 程序阻塞等待）。让 Go 程序在不需要时少用内存，整体更可靠。这也适用于\*\*过量分配（overcommit）\*\*场景（各容器内存上限之和 > 机器物理内存）。
* 当**运行环境不可控**且程序内存使用**与输入成比例**时，**不要**使用内存上限。

  * 如 CLI 工具或桌面应用。为未知输入/未知系统可用内存预设上限，可能导致令人困惑的崩溃与性能差。高级用户若需要，可自行设定上限。
* 当程序已接近环境内存极限时，**不要**通过设定内存上限来避免 OOM。

  * 这相当于用**严重降速**风险替换 OOM 风险，通常得不偿失。更有效的做法是**提高环境内存限额**（之后再考虑设置上限），或**降低 GOGC**（比“抖动缓解”更干净的权衡）。

---

## 延迟（Latency）

本文的可视化把应用建模为“在 GC 执行时**暂停**”。确有此类实现，称“**Stop-The-World（STW）**”GC。

然而，Go 的 GC 并非完全 STW，大多数工作与应用**并发**执行。这样做主要为降低**延迟**（例如单个计算单元的端到端时长，如一次 Web 请求）。此前我们主要考虑的是**吞吐**（如每秒请求数）。对于 Web 服务而言，虽然吞吐很重要，**单次请求的延迟**往往更重要。

就延迟而言，STW GC 可能需要相当长时间执行标记与清扫，在此期间应用（以及上下文中的“正在处理的请求”）无法推进。相反，Go GC 避免让全局暂停的长度与堆大小成比例；核心的追踪算法在应用执行期间完成。（暂停在算法上更与 GOMAXPROCS 成正比，但通常受“停止运行中的 goroutine 所需时间”主导。）并发收集并非没有成本：在实践中，它通常导致相比等价的 STW GC，吞吐更低。然而，“低延迟”并不天然意味着“低吞吐”；Go GC 的性能随时间稳步提升，**延迟与吞吐**均有所改进。

Go 当前 GC 的并发性并不使本文先前结论失效：GC 频率仍是**在 CPU 时间与内存之间做吞吐权衡**的主手段，事实上，它在**延迟**上也扮演此角色。因为 GC 的大部分成本发生在**标记阶段**。

**关键结论**：**降低 GC 频率**也可能带来**延迟改进**。这不仅适用于通过调参（如提高 GOGC/内存上限）降低频率，也适用于“优化指南”中提到的代码优化。

不过，延迟比吞吐更复杂，因为它是“每一时刻的程序执行”之产物，而非成本的简单聚合。因此，延迟与 GC 频率之间的联系不那么直接。以下列出一些可能的延迟来源，供深入探究：

* 在标记与清扫阶段切换时的短暂 STW 暂停；
* 标记阶段 GC 占用 **25%** CPU 资源导致的调度延迟；
* 当分配速率高时，用户 goroutine 进入\*\*GC 协助（assist）\*\*以让出时间；
* 在标记阶段，**指针写入屏障**引入的额外工作；
* 必须**挂起正在运行的 goroutine**以扫描其根。

这些延迟来源（除了“指针写入的额外工作”）在**执行跟踪**中可见。

---

## 终结器（Finalizers）、清理（Cleanups）与弱指针（Weak Pointers）

GC 用有限内存提供“**无限内存的幻觉**”：内存被分配但从不显式释放，使得 API 更简单、并发算法相较手动内存管理更容易。（一些手动管理的语言使用“智能指针”“编译期所有权追踪”等以确保释放，但这些特性深度嵌入语言的 API 设计约定。）

只有**存活对象**（从全局变量或某个 goroutine 的计算可达）才能影响程序行为。对象一旦**不可达（死亡）**，GC 就可在任意时刻安全回收。由此可以实现多种 GC 设计，如 Go 今天采用的追踪式设计。对象之死在语言层面**不可观测**。

但 Go 运行时提供了三个打破这一幻觉的特性：**清理（runtime.AddCleanup）**、**弱指针（weak.Pointer）**与**终结器（runtime.SetFinalizer）**。它们都提供了观察并对对象之死做出反应的方式，终结器甚至可以“**复活**”对象。这当然使程序更复杂，也给 GC 实现增加负担。但这些特性有其用武之地，Go 程序经常使用并从中获益。

各特性的细节请参阅其包文档（`runtime.AddCleanup`、`weak.Pointer`、`runtime.SetFinalizer`）。下面给出使用这些特性的一般建议、常见问题与测试建议。

### 通用建议

* **写单元测试**。
  这些特性的时机难以预测，容易出现细微错误。编写测试虽不易，但尤为重要。
* **避免在普通 Go 代码中直接使用**这些特性。
  它们是低层特性，行为/限制微妙。比如不保证在程序退出时运行清理或终结器，甚至**不保证一定会运行**。API 文档中的长注释就是警告。绝大多数 Go 代码不需要直接使用它们。
* **封装**这些机制在包内。
  尽可能不要让它们的使用泄露到你的公共 API；提供难以误用的接口。例如，不要要求用户在 C 分配的内存上设置清理以调用 `free`，而是在你提供的封装包内部隐藏细节。
* **限制访问**带有终结器/清理/弱指针的对象，使其仅在创建与设置它们的包内可达。
  例如 `unique` 包在内部使用弱指针，但完全**封装**被弱引用的对象；外部只能通过 `Value` 方法复制值。
* **优先对非内存资源进行显式、可预测的清理**，将清理/终结器作为兜底。

  * 对**内存类资源**（如 C 分配的内存、mmap 映射引用）而言，使用清理/终结器是合理的兜底。
  * 对**非内存资源**（文件描述符等），更应提供显式 `Close` 类 API。因为系统限制与 GC 时机不可控，使得仅依赖 GC 来释放非内存资源是糟糕的选择。建议把清理/终结器作为开发者错误的兜底（如 `os.File` 那样尽力关闭，或上报未显式清理）。
* **优先使用清理（cleanups）而非终结器（finalizers）**。
  终结器历史上用于简化 Go 与 C 的接口与非内存资源清理，因此其语义受限（每个对象仅一个、必须附着在对象首字节等）。更糟的是，终结器会**复活**对象，使其至少要等到**下一次 GC**才能复用该内存，且一旦处于**引用环**中就永远无法回收。除非确有复杂销毁顺序需求（清理顺序定义更弱），在 **Go 1.24 及以后**，推荐优先使用**清理**：更灵活、少错误、更高效。

### 清理的常见问题

* **带清理的对象不能从清理函数中可达**（例如通过闭包捕获）。否则对象无法回收，清理永远不会运行：

  ```go
  f := new(myFile)
  f.fd = syscall.Open(...)
  runtime.AddCleanup(f, func(fd int) {
      syscall.Close(f.fd) // 错误：引用了 f，清理不会运行！
  }, f.fd)
  ```
* **带清理的对象不能从清理函数的参数可达**。否则同样无法回收且不会运行（此特例还会 panic）：

  ```go
  f := new(myFile)
  f.fd = syscall.Open(...)
  runtime.AddCleanup(f, func(f *myFile) {
      syscall.Close(f.fd)
  }, f) // 错误
  ```
* 终结器有良好定义的执行顺序，而清理**没有**；清理之间也可能并发执行。
* **长时间运行**的清理应新起 goroutine，避免阻塞其他清理。
* `runtime.GC` 不会等待清理**执行完成**，只会等待它们**入队**。

### 弱指针的常见问题

* 弱指针的 `Value` 可能在**意料之外的时刻**返回 `nil`。务必做 `nil` 检查并准备兜底方案。
* 作为 map 的 key 使用弱指针时，它不会影响 map value 的可达性。因此，如果弱指针 key 所指对象也能从 value 可达，那么该对象仍被视为可达。

### 终结器的常见问题

* **带终结器的对象不能在任何路径上从其自身可达**（不可处于**引用环**）。否则对象无法回收、终结器也无法运行：

  ```go
  f := new(myCycle)
  f.self = f // 错误：f 从 f 可达
  runtime.SetFinalizer(f, func(f *myCycle) { ... })
  ```
* **带终结器的对象不能从终结器函数可达**（例如闭包捕获）：

  ```go
  f := new(myFile)
  f.fd = syscall.Open(...)
  runtime.SetFinalizer(f, func(_ *myFile) {
      syscall.Close(f.fd) // 错误：引用了外部的 f
  })
  ```
* **链式结构**（如带终结器的链表）至少需要与链长相同的 GC 周期数才能完全回收。**保持终结器浅**：

  ```go
  // 错误：这条 10 节点链表至少需要 10 次 GC 周期才能全部回收
  node := new(linkedListNode)
  for range 10 {
      tmp := new(linkedListNode)
      tmp.next = node
      node = tmp
      runtime.SetFinalizer(node, func(node *linkedListNode) { ... })
  }
  ```
* 避免在**包边界返回的对象**上设置终结器。这允许使用者调用 `runtime.SetFinalizer` 修改你的终结器，可能造成意外且被依赖的行为。
* **长时间运行**的终结器应新起 goroutine，以免阻塞其他终结器。
* `runtime.GC` 不会等待终结器**执行完成**，只会等待它们**入队**。

### 测试对象之死

使用这些特性时，编写鲁棒测试并不容易。建议：

* 避免与其他测试**并行**运行；尽可能提升确定性，掌握全局状态。
* 在进入测试时调用 `runtime.GC` 建立基线；使用 `runtime.GC` 让弱指针变 `nil`，并把清理/终结器入队。
* `runtime.GC` **不会**等待清理/终结器执行完成，只保证**入队**。
* 为了更鲁棒，**注入阻塞手段**：例如给清理/终结器传可选的 `chan`，执行完后写入该通道；若太难，可轮询某个“清理后状态”为真（如 `os` 测试里循环 `runtime.Gosched` 并检查文件是否已关闭）。
* 若测试终结器，且存在**对象链**，你至少需要调用 `runtime.GC` 的次数等于链的最深长度，才能确保所有终结器运行。
* 在 **race 模式**下测试，以发现清理/终结器与代码库其他部分之间的竞争。

---

## 其他资源

若要深入理解 Go GC 设计中的成本与权衡，参考：

* **The GC Handbook**——关于垃圾回收设计的优秀通用资源。
* **TCMalloc**——C/C++ 分配器 TCMalloc 的设计文档；Go 分配器参考了它。
* **Go 1.5 GC 公告**——宣布 Go 1.5 并发 GC 的博客，含更详尽算法描述。
* **Getting to Go**——截至 2018 年的 Go GC 演进深度演讲。
* **Go 1.5 并发 GC 节奏控制（pacing）**——关于何时启动并发标记阶段的设计文档。
* **更智能的回收（Smarter scavenging）**——关于 Go 运行时如何把内存归还给操作系统的设计文档。
* **可扩展页分配器**——Go 运行时如何管理从操作系统获取的内存的设计文档。
* **GC 节奏器重设计（Go 1.18）**——重新设计“何时启动并发标记”的算法。
* **软内存上限（Go 1.19）**——软内存上限的设计文档。

---

## 关于虚拟内存的说明

本文主要关注 GC 的**物理内存**使用，但经常有人问它与**虚拟内存**（如 top 中的 VSS）有何关系。

**物理内存**是电脑中 RAM 芯片实际容纳的内存。**虚拟内存**是操作系统提供的物理内存抽象，用于隔离进程；通常也允许保留不映射到任何物理地址的虚拟地址空间。

由于虚拟内存只是操作系统维护的映射，保留大块未映射的虚拟地址空间通常**很便宜**。

Go 运行时在多处依赖这种观点：

* Go 运行时**从不删除**映射过的虚拟内存；而是使用系统提供的特殊操作**释放**与某虚拟内存区间关联的物理内存资源。

  * 这用于实现内存上限与把不再需要的内存归还 OS。Go 运行时也会在后台持续释放。不详述，见“其他资源”。
* 在 32 位平台，Go 运行时会**预留** 128–512 MiB 的地址空间给堆，以限制碎片问题。
* Go 运行时在若干内部数据结构的实现中使用**大块虚拟地址空间预留**。在 64 位平台，这些结构的**最小**虚拟内存占用约 **700 MiB**；在 32 位平台几乎可忽略。

因此，像 top 中的 “VSS” 这类虚拟内存指标通常**不利于**理解 Go 程序的内存足迹。应关注 “**RSS**” 等更直接反映**物理内存**使用的指标。

---

## 优化指南

### 识别成本

在尝试优化应用与 GC 的交互之前，首先要确认 GC 确实是主要成本来源。

Go 生态提供了多种诊断与优化工具（参阅“诊断指南”）。这里聚焦一部分与大致顺序：

**CPU Profiling（CPU 分析）**

* 作为起点，CPU 分析能总体展示 CPU 时间花在哪儿。理解 GC 的角色主要在于识别 `runtime` 包中的若干函数。以下是几个解读 CPU Profile 时有用的符号（通常使用 `pprof top -cum` 或 `list` 查看**累计百分比**）。

  * `runtime.gcBgMarkWorker`：后台标记 worker 的入口。时间随 GC 频率与对象图规模/复杂度扩张，代表标记与扫描的基线成本。

    * 其中会见到 `runtime.gcDrainMarkWorkerDedicated/Fractional/Idle`，分别指不同类型的 worker。在基本空闲的程序中，GC 会利用**空闲 CPU**更快完成工作（Idle worker 时间可能看起来占比很大）。当程序更活跃时，这部分会下降。一个常见原因是程序只用一个 goroutine 运行，而 `GOMAXPROCS>1`。
  * `runtime.mallocgc`：堆分配入口。若累计时间很大（>15%），通常意味着分配很多。
  * `runtime.gcAssistAlloc`：goroutine 进入以协助 GC 标记/扫描的函数。若累计时间很大（>5%），表明应用分配速度可能**跑赢** GC，GC 影响较大；它也计入 `mallocgc` 调用树，会抬高后者。

**Execution Traces（执行跟踪）**

* CPU 分析反映**聚合**成本，但对**罕见/微妙/与延迟相关**的问题不敏感。执行跟踪提供了短时间窗口内**丰富而深入**的视图，包含大量与 GC 相关的事件并可直接观察应用交互路径。所有 GC 事件在 trace viewer 中都有标签。

**GC Traces（GC 跟踪日志）**

* 当其他方法不足时，GC 提供了专门的跟踪日志，能更深入地洞察行为。它们通过设置 `GODEBUG` 输出到 STDERR，每个 GC 周期一行。主要用于调试 GC 本身，需了解更多实现细节。

  * `GODEBUG=gctrace=1`：核心 GC 跟踪。输出格式见 `runtime` 文档中环境变量部分。
  * `GODEBUG=gcpacertrace=1`：更深入的“节奏器”跟踪。解读需要了解 GC pacer（见“其他资源”）。

### 消除堆分配

减少 GC 成本的一条路是让 GC **更少地管理**值。正如前文 GOGC 所示，程序的**分配速率**是决定 GC 频率的关键，因此以下技巧有时能带来最大的性能改进。

**堆内存分析（Heap profiling）**

* 在确认 GC 成本显著后，下一步是找出**分配热点**。内存（堆）分析非常有用。它按“发起分配的调用栈”归因。
* 每份堆分析可从四个维度查看：

  * `inuse_objects`：按**存活对象数**分解；
  * `inuse_space`：按**存活对象字节数**分解；
  * `alloc_objects`：程序启动以来**分配对象数**；
  * `alloc_space`：程序启动以来**分配字节数**。
* 为降低 GC 成本，`alloc_space` 通常最有用，它直接对应分配速率，能指示最该优化的热点。
* 采样默认只覆盖部分堆对象，但足以定位热点。采样率可经 `runtime.MemProfileRate` 调整。

**逃逸分析（Escape analysis）**

* 确定热点后，如何消除分配？关键在于**利用编译器的逃逸分析**，让其把内存放到**更高效**的存储（如栈）。Go 编译器能输出为何某个值逃逸的信息，据此重构代码以改变分析结果（往往是最难的部分）。
* 获取逃逸信息的方式：

  * 命令行：`go build -gcflags=-m=3 [package]`
  * 编辑器（如 VS Code）LSP 覆盖：命令“Source Action... > Show compiler optimization details”（或“Go: Toggle compiler optimization details”），将 `ui.diagnostic.annotations` 配置加入 `escape`。
  * 也可通过 JSON 机器可读格式构建定制工具（见 Go 源码文档）。

### 与实现相关的优化

Go GC 对**存活内存的人口统计特征**很敏感：复杂的对象图限制并行性并产生更多工作。因此 GC 对一些常见结构做了优化。最直接可用的包括：

* **无指针值**会与其他值**隔离存放**。

  * 若可能，消除数据结构中的指针可减少 GC 对程序的缓存压力。以“索引替代指针”的结构虽然类型约束弱一些，但可能更快。仅当对象图复杂且 GC 在标记/扫描上花大量时间时才值得这么做。
* **GC 会在值中的最后一个指针处停止扫描**。

  * 因此，把 struct 的指针字段**集中放在前部**可能有利（目前编译器不会自动重排；字段顺序按源码书写）。同样地，尽量用**索引**而非指针（例如切片下标）可减少 GC 成本。

### Linux 透明大页（THP）

CPU 需要把程序访问的**虚拟地址**翻译为**物理地址**。它通过“**页表**”完成，该结构由操作系统管理。每个条目代表一块不可再分的物理内存——“**页**”。

**透明大页（THP）**是 Linux 的一个特性：把连续的虚拟内存映射背后的物理页**透明替换**为更大的“**大页**”。大页减少了表示同一内存区域所需的页表项，提高查表速度。但如果只使用了大页的一小部分，**浪费**会更大。

在生产环境运行 Go 程序时，启用 THP 通常能以**更多内存**为代价，**提升吞吐与降低延迟**。小堆应用往往收益不大，反而可能增加显著内存（高达 50%）。但\*\*大堆（≥1 GiB）\*\*应用往往收益可观（吞吐提升可达 10%），额外内存开销很小（1–2% 以内）。了解你的 THP 设置并进行实验很重要。

可通过修改 `/sys/kernel/mm/transparent_hugepage/enabled` 启用/禁用 THP（详见官方 Linux 管理手册）。若在生产中启用 THP，我们建议：

* 将 `/sys/kernel/mm/transparent_hugepage/defrag` 设为 `defer` 或 `defer+madvise`。

  * 该设置控制内核合并普通页为大页的激进程度。`defer` 表示**懒合并、后台进行**。更激进的设置会在内存紧张时引入停顿、伤害延迟。`defer+madvise` 类似，但对明确请求大页的应用更友好。
* 将 `/sys/kernel/mm/transparent_hugepage/khugepaged/max_ptes_none` 设为 `0`。

  * 该设置控制内核守护进程为分配大页时可额外分配多少页。默认**极度激进**，常常**抵消** Go 运行时把内存归还 OS 的努力。Go 1.21 之前，运行时尝试缓解默认设置的负面影响，但有 CPU 代价。Go 1.21+ 与 Linux 6.2+ 上，Go 运行时不再修改大页状态。
  * 如果升级到 Go 1.21.1+ 后内存使用上升，尝试该设置；很可能能解决。备选方案：调用 `Prctl(PR_SET_THP_DISABLE)` 在进程级禁用大页，或设置 `GODEBUG=disablethp=1`（将在 Go 1.21.6 与 1.22 提供）来禁用**堆内存**的大页。注意该 GODEBUG 可能在未来移除。

---

## 附录：关于 GOGC 的附加说明

文中声称“**将 GOGC 翻倍，会使堆内存开销翻倍，并把 GC CPU 成本减半**”。推导如下：

首先，目标堆大小主要影响**新堆**（存活堆由应用决定）：

> 目标堆 = 存活堆 + （存活堆 + GC 根）× GOGC / 100

> 总堆 = 存活堆 + 新堆

⇒ **新堆** = （存活堆 + GC 根）× GOGC / 100

可见把 GOGC 翻倍会把每个周期可分配的新堆**翻倍**（即堆内存开销倍增）。注意（存活堆 + 根）近似为 GC 需扫描的内存量。

再看 GC CPU 成本。总成本 = 每周期成本 × 周期频率 × 时间窗 T。

> 每周期 GC CPU 成本 = （存活堆 + 根）× 每字节成本 + 固定成本

稳态下，分配速率与每字节成本恒定。周期频率由新堆决定：

> 周期频率 = 分配速率 / 新堆 = 分配速率 / \[（存活堆 + 根）× GOGC / 100]

合并：

> 总 GC CPU 成本 = $分配速率 / ((存活堆+根)×GOGC/100)$ × $((存活堆+根)×每字节成本 + 固定成本)$ × T

对于足够大的堆（多数情况），**边际成本**主导，固定成本可忽略，得：

> 总 GC CPU 成本 = 分配速率 / (GOGC/100) × 每字节成本 × T

由此可见，**GOGC 翻倍 ⇒ 总 GC CPU 成本减半**。此外，GC CPU 成本主要由**分配速率**与**每字节扫描成本**决定。如何具体降低它们，见“优化指南”。

> 注：存活堆大小与 GC 实际需要扫描的内存量之间存在差异：相同大小但不同结构的存活堆，会导致不同的 CPU 成本（但**内存成本相同**），从而出现不同的权衡。这也是为什么在稳态的定义中包含“堆的结构”。从更近似的角度看，目标堆应只包含**可扫描的存活堆**，但当“可扫描部分很小而存活堆很大”时会出现退化行为，因此并未这么做。

---

> 版权、服务条款、隐私政策等内容从略；本译文仅供学习参考。
